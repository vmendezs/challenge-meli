{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8e1eb51-8cde-469b-ae6c-d1fb4230a42b",
   "metadata": {},
   "source": [
    "# 3. Similitud entre productos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739b950b",
   "metadata": {},
   "source": [
    "## Descripción\n",
    "Un desafío constante en MELI es el de poder agrupar productos similares utilizando algunos atributos de estos como pueden ser el título, la descripción o su imagen. Para este desafío tenemos un dataset “items_titles.csv” que tiene títulos de 30 mil\n",
    "productos de 3 categorías diferentes de Mercado Libre Brasil\n",
    "## Entregable\n",
    "El objetivo del desafío es poder generar una Jupyter notebook que determine cuán similares son dos títulos del dataset “item_titles_test.csv” generando como output un listado de la forma\n",
    "\n",
    "\n",
    "| ITE_ITEM_TITLE | ITE_ITEM_TITLE | Score Similitud (0,1) |\n",
    "|-----------|-----------|-----------|\n",
    "| Zapatillas Nike   | Zapatillas Nike   | 1 |\n",
    "| Zapatillas Nike   | Zapatillas Adidas | 0,5 |\n",
    "\n",
    "donde ordenando por score de similitud podamos encontrar los pares de productosmás similares en nuestro dataset de test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649498ae",
   "metadata": {},
   "source": [
    "## Desarrollo del código\n",
    "\n",
    "### 1. Intalación de la libreria de levenshtein\n",
    "Esta libreria es necesaria para encontrar la similitud que existe ente los dos títulos comparados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "693313ea-99df-4269-9a32-5977b62c2ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install python-levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac2a4a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46273e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579efd07",
   "metadata": {},
   "source": [
    "Reiniciar el kernel para continuar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6497541",
   "metadata": {},
   "source": [
    "### 2. Importe de librerias necesarias para la transformación del dataset\n",
    "- **pandas** para el manejo del dataset como dataframe.\n",
    "- **re** para expresiones regulares, permite buscar y manipular patrones en cadenas de texto.\n",
    "- **numpy** para cálculos numéricos y operaciones con matrices y arreglos.\n",
    "- **ntlk** para NLP\n",
    "- **Levenshtein** para encontrar el score\n",
    "- **unidecode** para manejo de tildes\n",
    "- **sklearn** para el modelo de entrenamiento sobre variables categóricas\n",
    "- **spacy** para data cleaning de los valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0805dce4-9a8f-49f4-8730-d65eb06dc9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\valeria.mendez\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\valeria.mendez\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\valeria.mendez\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\valeria.mendez\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "import Levenshtein as lv\n",
    "from unidecode import unidecode\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import spacy\n",
    "from spacy.lang.pt import Portuguese\n",
    "\n",
    "# Descargar recursos adicionales para NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Cargar modelo de lenguaje para el procesamiento de portugués en spaCy\n",
    "nlp = Portuguese()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c0a6b8",
   "metadata": {},
   "source": [
    "### 3. Lectura del dataset\n",
    "Este se encuentra contenido dentro de la misma ruta de este notebook por lo que se puede realizar la lectura directamente con el nombre del archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f00354b-c156-4998-aa83-fc6021b90520",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items_titles = pd.read_csv('items_titles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8bc390",
   "metadata": {},
   "source": [
    "### 4. Limpieza de la base\n",
    "Dentro del campo *ITE_ITEM_TITLE* se deben limpiar los valores para asegurar que la distancia de levenshtein sea la más fiel posible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea5ec09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para eliminar *stop word* que hacen referencia a palabras conectores en portugues\n",
    "def preprocess_text(text):\n",
    "    # Tokenizar el texto en palabras\n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Eliminar stop words\n",
    "    stop_words = set(stopwords.words('portuguese'))\n",
    "    words = [word for word in words if word.lower() not in stop_words]\n",
    "    \n",
    "    # Lematización\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    \n",
    "    # Unir las palabras preprocesadas en un nuevo texto\n",
    "    preprocessed_text = ' '.join(words)\n",
    "    return preprocessed_text\n",
    "\n",
    "# Función para eliminar las palabras conectores utilizando expresiones regulares\n",
    "def quitar_conectores(texto):\n",
    "    for conector in conectores_a_eliminar:\n",
    "        texto = re.sub(r'\\b' + re.escape(conector) + r'\\b', '', texto, flags=re.IGNORECASE)\n",
    "    return texto\n",
    "\n",
    "# Función para quitar caracteres especiales utilizando expresiones regulares\n",
    "def quitar_caracteres_especiales(texto):\n",
    "    texto = re.sub(r'[^\\w\\s,]', '', texto)\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628fe54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizamos la función *def preprocess_text(text):* para quitar stop words\n",
    "df_items_titles['Texto_Limpio'] = df_items_titles['ITE_ITEM_TITLE'].apply(preprocess_text)\n",
    "\n",
    "# Eliminamos los espacios en blanco (espacios, tabulaciones, saltos de línea) del principio y final.\n",
    "df_items_titles['Texto_Limpio'] = df_items_titles['Texto_Limpio'].str.strip()\n",
    "\n",
    "# Colocamos el texto en minusculas\n",
    "df_items_titles['Texto_Limpio'] = df_items_titles['Texto_Limpio'].str.lower()\n",
    "\n",
    "# Aplicamos unidecode() para quitar los tildes de los caracteres acentuados en la columna 'columna'\n",
    "df_items_titles['Texto_Limpio'] = df_items_titles['Texto_Limpio'].apply(lambda x: unidecode(x))\n",
    "\n",
    "# Lista de palabras conectores a eliminar\n",
    "conectores_a_eliminar = ['-',',']\n",
    "\n",
    "# Aplicamos la función para quitar caracteres especiales y conectores\n",
    "df_items_titles['Texto_Limpio'] = df_items_titles['Texto_Limpio'].apply(quitar_conectores)\n",
    "df_items_titles['Texto_Limpio'] = df_items_titles['Texto_Limpio'].apply(quitar_caracteres_especiales)\n",
    "\n",
    "# Termino la limpieza con la eliminación de las comas\n",
    "df_items_titles['Texto_Limpio'] = df_items_titles['Texto_Limpio'].str.replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d6ede6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos una pequeña muestra de la columna limpia con el titulo del item\n",
    "print(df_items_titles.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010f4a53",
   "metadata": {},
   "source": [
    "### 5. Clasificación de categoría según el nombre del artículo\n",
    "Esta es una primera clasificacion teniendo en cuenta palabras clave dentro del nombre del título del producto.\n",
    "\n",
    "##### Exploración inicial\n",
    "Realicé una exploración previa de las palabras con más frecuencia y posteriormente las coloque en tres categorías:\n",
    "- Calzado: Incluye tenis, zapatillas, botas, marcas de zapatos, referencias de zapatos\n",
    "- Bicicleta: Incluye pabras como bicicleta en inglés y español y marcas de productos de ciclismo\n",
    "- TV: En donde se incluyen articulos relacionados con televisores, marcas de televisores y pantallas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb77f677",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_valores_unicos = df_items_otros['Texto_Limpio'].nunique()\n",
    "# Crear una lista de todas las palabras en el DataFrame\n",
    "todas_las_palabras = ' '.join(df_items_titles['Texto_Limpio']).split()\n",
    "\n",
    "# Calcular la frecuencia de cada palabra\n",
    "frecuencia_palabras = pd.Series(todas_las_palabras).value_counts()\n",
    "print(\"cantidad de palabras: \", len(frecuencia_palabras))\n",
    "print(frecuencia_palabras.head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149d63f9",
   "metadata": {},
   "source": [
    "### 5.1. Categorización manual\n",
    "Cree la función *categorizar_titulos(df, column):* para hacer una categorización manual de los productos de acuerdo a la primera exploración que vi de los valores que pueden contener las palabras y se frecuencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16627679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorizar_titulos(df, column):\n",
    "    key_word_zapatos = ['tenis', 'sapatilha', 'sapato', 'sapatos', 'adidas', 'puma', 'nike', 'all star', 'air', 'slip', 'babuche', 'vans', 'tennis', 'sandalia', 'mizuno', 'shoes', 'zapatillas', 'calcado', 'calcados', 'bota', 'sapatenis', 'jordan', 'sneaker', 'new balance', 'botinha', 'chuteira']\n",
    "    key_word_bicicleta = ['bike', 'bicicleta', 'specialized', 'bikes', 'bici', 'byke', 'motocicleta', 'oakley', 'bmx', 'shimano', 'disc']\n",
    "    key_word_tv = ['tv', 'tela', 'televisao', 'televisor', 'samsung', 'panasonic', 'monitor']\n",
    "\n",
    "    categorias = {\n",
    "        'calzado': key_word_zapatos,\n",
    "        'bicicleta': key_word_bicicleta,\n",
    "        'tv': key_word_tv\n",
    "    }\n",
    "\n",
    "    # Inicializamos la columna 'Categoria' con valor 'otros'\n",
    "    df['Categoria_Manual'] = 'otros'\n",
    "\n",
    "    # Utilizamos un bucle para asignar la categoría adecuada a cada título\n",
    "    for categoria, palabras_clave in categorias.items():\n",
    "        for palabra in palabras_clave:\n",
    "            df['Categoria_Manual'] = np.where(df[column].str.contains(palabra, case=False), categoria, df['Categoria_Manual'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917d9221",
   "metadata": {},
   "source": [
    "En las siguientes líneas validamos la distribución de los items con la clasificación manual por key words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29970728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso de la función:\n",
    "df_items_titles = categorizar_titulos(df_items_titles, 'Texto_Limpio')\n",
    "\n",
    "# Calcular el conteo de cada variable en la columna 'respuestas'\n",
    "conteo_variables = df_items_titles['Categoria_Manual'].value_counts()\n",
    "\n",
    "# Calcular el porcentaje representativo de cada variable\n",
    "porcentaje_representativo = conteo_variables / len(df_items_titles) * 100\n",
    "\n",
    "print(\"Items:\\n\", conteo_variables, \"\\n\", \"Porcentajes representativos:\\n\", porcentaje_representativo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f511660d",
   "metadata": {},
   "source": [
    "### 5.2. Categorización a través de un modelo ML\n",
    "Para optimizar más la clasificación manual, vamos a tomar la clasificación manual anterior como un conjunto de entrenamiento etiquetado para realizar el entrenamiento de modelo *MultinomialNB()* a partir de la vectorización de variables categóricas llamado *TfidfVectorizer()*, el cual consiste en darle un valor numérico a cada título de producto. De tal manera obtendremos una mejor salida de los tres grupos de clasificación existentes en el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b30e166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos para cada clasificación\n",
    "df_calzado = df_items_titles[df_items_titles['Categoria_Manual'] == 'calzado']\n",
    "df_tv = df_items_titles[df_items_titles['Categoria_Manual'] == 'tv']\n",
    "df_bicicletas = df_items_titles[df_items_titles['Categoria_Manual'] == 'bicicleta']\n",
    "df_otros = df_items_titles[df_items_titles['Categoria_Manual'] == 'otros']\n",
    "\n",
    "# Seleccionar una cantidad similar de registros para cada clasificación\n",
    "min_len = min(len(df_calzado), len(df_tv), len(df_bicicletas), len(df_otros))\n",
    "df_calzado_sampled = df_calzado.sample(min_len, random_state=42)\n",
    "df_tv_sampled = df_tv.sample(min_len, random_state=42)\n",
    "df_bicicletas_sampled = df_bicicletas.sample(min_len, random_state=42)\n",
    "df_otros_sampled = df_otros.sample(min_len, random_state=42)\n",
    "\n",
    "# Unir los datos en un nuevo DataFrame balanceado\n",
    "df_balanced = pd.concat([df_calzado_sampled, df_tv_sampled, df_bicicletas_sampled, df_otros_sampled], ignore_index=True)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y test\n",
    "X = df_balanced['Texto_Limpio']\n",
    "y = df_balanced['Categoria_Manual']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a84d0f",
   "metadata": {},
   "source": [
    "##### Vectorización de variables categóricas\n",
    "A continuación hago uso de la función **TfidfVectorizer()** que me permite convertir los valores categoricos de *ITE_ITEM_TITLE*  en una matriz numérica que puede ser utilizada como entrada para el modelo de ML, en otras palabras toma el texto y lo convierte en valores numéricos a través de Tokenización, Construcción del vocabulario y Cálculo del TF-IDF que es la puntuación para cada palabra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86948a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorización del campo de ITE_ITEM_TITLE porque es una variable categórica\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectors = vectorizer.fit_transform(X_train)\n",
    "X_test_vectors = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cabf78",
   "metadata": {},
   "source": [
    "##### Escoger el modelo de entrenamiento\n",
    "\n",
    "Escogí como modelo de clasificación **MultinomialNB()**, ya que crea un modelo simple de clasificación Naive Bayes multinomial. Esto se traduce en que el algoritmo Naive Bayes, al ser un clasificador probabilístico basado en el teorema de Bayes, toma independencia condicional entre las características de la variable de predicción y el valor de la variable objetivo/a predecir. Este modelo, adicionalmente tiene un componente de clasificación multinomial la cual se desenvuelve correctamente en problemas como este sobre análisis y clasificación de texto.\n",
    "\n",
    "Algunas razones por las que funciona bien dentro del contexto de este reto:\n",
    "- Clasificador Multinomial: MultinomialNB está diseñado para trabajar con características categóricas, como recuentos de palabras.\n",
    "- Suavizado (Smoothing): MultinomialNB aplica suavizado (también conocido como corrección de Laplace) para evitar problemas de probabilidad cero cuando una palabra en un documento no aparece en los datos de entrenamiento.\n",
    "- Vectorizer: Puedo utilizar las características obtenidas de la vectorización (la matriz TF-IDF)\n",
    "- Evaluación: Puedo evaluar el rendimiento del modelo de maner sencilla como lo son metricas de accuracy, precision, recall, F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e632fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrenamiento del modelo\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c1f701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar predicciones y evaluar el modelo\n",
    "y_pred = model.predict(X_test_vectors)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "classification_report_output = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", classification_report_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54a0b02",
   "metadata": {},
   "source": [
    "Como se puede observar, tenemos un Accuracy mayor al 80% y considero que fue un modelo correctamente entrenado por las siguientes razones:\n",
    "1. El Accuracy representa la proporción de predicciones correctas que hizo el modelo con respecto al total de muestras en el conjunto de datos.\n",
    "2. Evaluación del Precision: Al tener un valor por encima del 70%, significa que el modelo está realizando correctamente sus predicciones en la mayoría de las muestras.\n",
    "3. Overfitting: Un valor de Accuracy muy alto (cercano al 100%) puede indicar que el modelo está sobreajustando los datos de entrenamiento. Esto significa que el modelo se ha \"memorizado\" los datos de entrenamiento en lugar de aprender patrones generales, y por tanto no es capaz de enfrentarse a datos desconocidos y eso implicaria un rendimiento bajo a futuro.\n",
    "4. Data Balanceada: Al tener una base de datos de entrenamiento balanceada en la cantidad de items por categoría, evito tener una categoría dominante, un modelo puede lograr un alto accuracy simplemente prediciendo siempre la clase dominante. Esto lo único que significa es que el modelo no logra hacer predicciones significativas para las categorías con una cantidad de items pequeña."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25399d93",
   "metadata": {},
   "source": [
    "### 5.3. Clasificación del dataset original\n",
    "Teniendo en cuenta que el modelo ya fue entrenado, tomare la columna de *Texto_limpio* del dataset y realizaré una nueva clasificación para refinar las categorías posibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1782e7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener todos los valores de titulos de dataset\n",
    "X_all = df_items_titles[df_items_titles['Categoria_Manual'] == 'otros']['Texto_Limpio']\n",
    "\n",
    "# Vectorizar los títulos del dataset\n",
    "X_all_vectors = vectorizer.transform(X_all)\n",
    "\n",
    "# Predicción de la nueva categoría\n",
    "y_pred_all = model.predict(X_all_vectors)\n",
    "\n",
    "# Paso la columna 'Categoria_Manual' para mantener los valores originales\n",
    "df_items_titles['Nueva_Clasificacion'] = df_items_titles['Categoria_Manual']\n",
    "\n",
    "# Pasa los valores de la 'Categoria_Manual' con la 'Nueva_Clasificacion' \n",
    "df_items_titles.loc[df_items_titles['Categoria_Manual'] == 'otros', 'Nueva_Clasificacion'] = y_pred_all\n",
    "\n",
    "# Elimino la columna de para quedarme unicamente con la columna que tiene el titulo limpio\n",
    "df_items_titles = df_items_titles.drop('ITE_ITEM_TITLE', axis=1)\n",
    "\n",
    "# Dejo como posibilidad guardar el nuevo dataframe con las predicciones de categorías\n",
    "df_items_titles.to_csv('nuevo_dataframe_con_predicciones.csv', sep = '|', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12650247",
   "metadata": {},
   "source": [
    "##### Opcional\n",
    "A continuación, evalúo que la categoría que cree de \"otros\" sea bastante pequeña para no ser tenida en cuenta. Al ser el 1,76% de la base de 30mil registros, no tomaré en cuenta estos valores ya que pueden haber valores basura o que necesitan de más características para ser clasificados en alguna de las 3 categorías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad53d5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el conteo de cada variable en la columna 'respuestas'\n",
    "conteo_variables = df_items_titles['Nueva_Clasificacion'].value_counts()\n",
    "\n",
    "# Calcular el porcentaje representativo de cada variable\n",
    "porcentaje_representativo = conteo_variables / len(df_items_titles) * 100\n",
    "\n",
    "print(\"Items:\\n\", conteo_variables, \"\\n\", \"Porcentajes representativos:\\n\", porcentaje_representativo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cbaccd",
   "metadata": {},
   "source": [
    "### 6. Función para calcular el score de similitud\n",
    "A continuación se encuentra la función que calcula la similitud entre dos titulos.\n",
    "**Descripción de campos:**\n",
    "- df: Corresponde al dataframe en el cual se va a evaluar la similitud.\n",
    "- num_items_1: Corresponde al numero de items sobre los que se quiere investigar. Ejemplo: 1 equivale al primer titulo de todo el dataset, 2 a los dos primeros titulos de todo el dataset, etc...\n",
    "- num_items_2: Corresponde al numero de items sobre los que se desea iterar en un mismo item. Ejemplo: Si coloca 10, va a tomar los 10 primeros items de todo el dataset para ser comparados contra la cantidad de items que colocó en num_items_1.\n",
    "- titulos: Corresponde a la columna donde se encuentran los titulos de los productos.\n",
    "- categoria_nombre: Corresponde al nombre de la columna que contiene la categoría que se desea evaluar.\n",
    "- categoría_filtro: Corresponde a la categoría que desea filtrar. En este caso esa variable puede tomar los valores de: calzado, bicicleta o tv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d67761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calcular_Score_Similitud(df, num_items_1, num_items_2, titulos, categoria_nombre, categoria_filtro):\n",
    "    # Filtrar el DataFrame por la categoría deseada\n",
    "    df_items = df.loc[df[categoria_nombre] == categoria_filtro]\n",
    "\n",
    "    # Crear un DataFrame para comparar textos\n",
    "    df_item_compare = pd.DataFrame({'Texto_1': df_items[titulos].tolist(), \n",
    "                                          'Texto_2': df_items[titulos].tolist()})\n",
    "    \n",
    "    # Creación de lista para almacenar las distancias como score de similitud\n",
    "    comparison_list = []\n",
    "    \n",
    "    # Creación de loop\n",
    "    # Primer for indica el item fijo por el cual se va a evualuar\n",
    "    for i in range(num_items_1):\n",
    "        text1 = df_item_compare['Texto_1'][i]\n",
    "        #Segundo for indica las veces que tiene que pasar el item del for anterior por cada uno de los items de este loop\n",
    "        for j in range(num_items_2):\n",
    "            text2 = df_item_compare['Texto_2'][j]\n",
    "            # Obtener el score de similitud a partir de la distancia de levenshtein\n",
    "            distance = lv.ratio(text1, text2)\n",
    "            # Datos en forma de lista de listas\n",
    "            datos = [df_item_compare['Texto_1'][i], df_item_compare['Texto_2'][j], distance]\n",
    "            comparison_list.append(datos)\n",
    "\n",
    "    # Nombres de las columnas para ser añadidos en un dataframe\n",
    "    cols = ['Texto_1', 'Texto_2', 'Score Similitud (0,1)']\n",
    "\n",
    "    # Crear el DataFrame utilizando pd.DataFrame()\n",
    "    df_compared = pd.DataFrame(comparison_list, columns=cols)\n",
    "    \n",
    "    # Devolver el dataframe con los dos titulos comparados y el score\n",
    "    return df_compared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e4b8cf",
   "metadata": {},
   "source": [
    "### 7. Score de similitud para la categoría de calzado\n",
    "En este caso estoy tomando los 3 primeros items de la categoría de calzado y los comparo con al menos 6 otras categorías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7836f4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamada a la función con el DataFrame original y la categoría deseada\n",
    "df_comparison_tenis = Calcular_Score_Similitud(df_items_titles, 3, 6, 'Texto_Limpio', 'Nueva_Clasificacion', 'calzado')\n",
    "print(df_comparison_tenis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798b09a3",
   "metadata": {},
   "source": [
    "### 8. Score de similitud para la categoría de bicicleta\n",
    "En este caso estoy tomando los 3 primeros items de la categoría de bicicletas y los comparo con al menos 6 otras categorías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be74975b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamada a la función con el DataFrame original y la categoría deseada\n",
    "df_comparison_tenis = Calcular_Score_Similitud(df_items_titles, 3, 6, 'Texto_Limpio', 'Nueva_Clasificacion', 'bicicleta')\n",
    "print(df_comparison_tenis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74852fa4",
   "metadata": {},
   "source": [
    "### 9. Score de similitud para la categoría de Televisores\n",
    "En este caso estoy tomando los 3 primeros items de la categoría de tv y los comparo con al menos 6 otras categorías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79882329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamada a la función con el DataFrame original y la categoría deseada\n",
    "df_comparison_tenis = Calcular_Score_Similitud(df_items_titles, 2, 6, 'Texto_Limpio', 'Nueva_Clasificacion', 'tv')\n",
    "print(df_comparison_tenis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
